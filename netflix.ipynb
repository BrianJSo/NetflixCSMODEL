{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Rise of LGBT shows\n",
    "Introduction thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is a collection of information about Netflix shows as of 2019. Each obsevation contains information about a Netflix show's unique ID, its type (i.e. whether it is a TV Show or a movie), title, director, cast, country (where it was produced), release date, release year, TV rating, duration, genre, and description.\n",
    "\n",
    "The dataset 'Netflix Movies and TV Shows' was collected from Flixable, a third-party Netflix search engine. Flixable was created in 2018 by Ville Salminen, and it came with additional advanced search functionality which was missing from the implemented search engine of Netflix. The data was extracted from the Flixable database through the use of API calls.\n",
    "\n",
    "Currently, Netlflix does not have their API publicly available, and Flixable has not openly disclosed how the web site was able to acquire the data for its database. Despite the popularity of the aforementioned site, we cannot confirm whether the dataset that was extracted from Flixable is reliable. Moreover, considering that the latest update for the dataset was on November 2019, the conclusions made in this case study may not be representative of the current Netflix shows as of September, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_csv(\"./netflix_titles.csv\")\n",
    "netflix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df['director'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates dito ba?? ewan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for `NAN`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the `description` and `listed_in` variables do not have `Nan`/`null` values. Hence, no need to drop rows (for this question, at least) or do imputation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `description` variable is a good feature to check for duplicates as the synopsis are expectedly unique for each show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_desc_duplicate = netflix_df['description'].value_counts().reset_index(name=\"description\").query(\"description > 1\")\n",
    "print(netflix_desc_duplicate)\n",
    "print(\"Repeated descriptions:\", len(netflix_desc_duplicate))\n",
    "print(\"Repeated shows:\", netflix_desc_duplicate['description'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 repeated descriptions, and a total of 15 repeated shows based on our assumption that observations with the same description are the same show. To further confirm this, we can look at the other variables of the observations corresponding to these descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df.loc[netflix_df[\"description\"].isin(netflix_desc_duplicate[\"index\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely examining the observations reveals that the only differences in the observations are the `date_added` and the `title` variables. The date when the show is added doesn't give much insight as it does not give relevant context to the similarity of the show (i.e. different versions of a show can be added at different times, and vice versa). However, the title &mdash; at least in the results above &mdash; are descriptive in the differences.\n",
    "\n",
    "The titles show that there are multiple versions due to langauge. The show *The Incredibles 2*, for instance, has both the original, and the Spanish version. Meanwhile, the movie *Oh! Baby* has two other versions: the Malalayam and Tamil. The only observation which didn't show any difference was for the movie *Sarkar* whose titles (there are 2 observations for this movie) do not indicate versions. This may either be a data collection error, or the title simply does not show which version it is.\n",
    "\n",
    "Nonetheless, all the duplicates will be cleaned in the same way. The \"original\" version (i.e. the one without a parenthesis stating the version, or if not applicable, the first entry that appears in the dataset for simplicity) will be retained. \n",
    "\n",
    "This step is important because duplicates will affect the weight of the words during feature extraction. Thus, there would be bias for a particular show which would produce results that are not representative of the show's listed genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are only few duplicates, we can manually remove the offending observations via `show_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_id_remove_list = [81186758, 81186757, 81072516, 81046962, 81059388, 81151877, 81074135, 81091424]\n",
    "\n",
    "netflix_df.loc[(netflix_df[\"description\"].isin(netflix_desc_duplicate[\"index\"])) & (~netflix_df[\"show_id\"].isin(show_id_remove_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the observations that will be retained from all the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_clean = netflix_df[~netflix_df[\"show_id\"].isin(show_id_remove_list)]\n",
    "netflix_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Most recurring genres in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_in_series = netflix_df_clean['listed_in']\n",
    "genre_matrix = []\n",
    "\n",
    "for string in listed_in_series:\n",
    "    split_str = string.split(', ')\n",
    "    genre_matrix.append(split_str)\n",
    "\n",
    "genre_df = pd.DataFrame(genre_matrix)\n",
    "genre_list = pd.concat([genre_df[0], genre_df[1], genre_df[2]])\n",
    "genre_list.dropna(inplace = True)\n",
    "genre_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genre_count = genre_list.value_counts()\n",
    "\n",
    "genre_count.plot.bar()\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar plot of genre count in Netflix shows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common association rules among Netflix genres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are Netflix descriptions effective classifiers for the LGBTQ genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `description` variable in the dataset refers to Netflix's synopsis of each show. DESCRIBE MORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get not LGBT shows same size as LGBT\n",
    "- Get features (tfidf, or whatever)\n",
    "- Get top features (chi2)\n",
    "- Tas ulet ulet sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_df_international = netflix_df_international[netflix_df_international[\"isInternationalMV\"] == True]\n",
    "netflix_df_international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_df_non_international = netflix_df_clean[netflix_df_clean[\"isInternationalMV\"] == False]\n",
    "netflix_df_non_international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_df_classifier = pd.concat([netflix_df_non_international, netflix_df_international])\n",
    "netflix_df_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(netflix_df_classifier[\"description\"])\n",
    "vector=vectorizer.transform(netflix_df_classifier[\"description\"])\n",
    "features = vectorizer.get_feature_names()\n",
    "xdata=vector.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linearSVC=svm.LinearSVC()\n",
    "\n",
    "skf=StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in skf.split(xdata, ydata):\n",
    "    x_train=xdata[train_index]\n",
    "    x_test=xdata[test_index]\n",
    "    y_train=np.array(ydata)[train_index]\n",
    "    y_test=np.array(ydata)[test_index]\n",
    "    \n",
    "    linearSVC = linearSVC.fit(x_train,y_train)\n",
    "\n",
    "    y_pred = linearSVC.predict(x_test)\n",
    "\n",
    "    confusion=confusion_matrix(y_test, y_pred, labels=['Not International Movie', 'International Movie'])\n",
    "    print('CONFUSION MATRIX: \\n', confusion) #order: tn, fp, fn, tp\n",
    "\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=['Not International Movie', 'International Movie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_reset = netflix_df_classifier.reset_index()\n",
    "\n",
    "ydata=[]\n",
    "b=0\n",
    "while b<len(netflix_reset):\n",
    "    if netflix_reset.loc[b, \"isInternationalMV\"] == True:\n",
    "        appenddata=\"International Movie\"\n",
    "    if netflix_reset.loc[b, \"isInternationalMV\"] == False:\n",
    "        appenddata=\"Not International Movie\"\n",
    "    ydata.append(appenddata)\n",
    "    b+=1\n",
    "\n",
    "ydata\n",
    "\n",
    "selector = SelectKBest(chi2, k=20)\n",
    "selector.fit(xdata, ydata)\n",
    "# Get idxs of columns to keep\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "\n",
    "chi_x = np.asarray(xdata)\n",
    "chi_x\n",
    "    \n",
    "scores, pval=(chi2(chi_x, ydata))\n",
    "scores\n",
    "\n",
    "for i in idxs_selected:\n",
    "    pval_add=(features[i], scores[i])\n",
    "    print(pval_add)\n",
    "    print(pval[i])\n",
    "\n",
    "# pvalue_continue= True\n",
    "# while pvalue_continue==True:\n",
    "#     try:\n",
    "#         pvalue_evaluation=input(\"what word\")\n",
    "#         pvalue_index=features.index(pvalue_evaluation)\n",
    "#         print(\"SCORE:\", scores[pvalue_index])\n",
    "#         print (\"PVALUE:\", (pval[pvalue_index]))\n",
    "\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
