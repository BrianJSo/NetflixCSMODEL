{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Shows\n",
    "Introduction thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is a collection of information about Netflix shows as of 2019. Each obsevation refers to a single show on the Netflix catalogue spread across 12 variables. The following are the descriptions of each variable in the dataset:\n",
    "\n",
    "- **`show_id`**: The unique ID of a particular show.\n",
    "- **`type`**: Indicates whether a particular show is a movie (Movie) or a TV show (TV Show).\n",
    "- **`title`**: The title of the show.\n",
    "- **`director`**: The director/s of the show.\n",
    "- **`cast`**: The actor/s involved with the show.\n",
    "- **`country`**: The country where the show was produced.\n",
    "- **`date_added`**: The date when the show was added on Netflix.\n",
    "- **`release_year`**: The year when the show was initially released.\n",
    "- **`rating`**: TV parental guideline rating of the show.\n",
    "- **`duration`**: Total duration of the show measured in minutes for movies and in seasons for TV shows.\n",
    "- **`listed_in`**: Genre/s of the show\n",
    "- **`description`**: Textual description of the show\n",
    "\n",
    "\n",
    "The dataset 'Netflix Movies and TV Shows' was collected from Flixable, a third-party Netflix search engine. Flixable was created in 2018 by Ville Salminen, and it came with additional advanced search functionality which was missing from the implemented search engine of Netflix. The data was extracted from the Flixable database through the use of API calls.\n",
    "\n",
    "Currently, Netlflix does not have their API publicly available, and Flixable has not openly disclosed how the web site was able to acquire the data for its database. Despite the popularity of the aforementioned site, we cannot confirm whether the dataset that was extracted from Flixable is reliable. Moreover, considering that the latest update for the dataset was on November 2019, the conclusions made in this case study may not be representative of the current Netflix shows as of September, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rule_miner import RuleMiner\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_csv(\"./netflix_titles.csv\")\n",
    "netflix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df['director'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates dito ba?? ewan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for `NAN`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the `description` and `listed_in` variables do not have `Nan`/`null` values. Hence, no need to drop rows (for this question, at least) or do imputation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `description` variable is a good feature to check for duplicates as the synopsis are expectedly unique for each show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_desc_duplicate = netflix_df['description'].value_counts().reset_index(name=\"description\").query(\"description > 1\")\n",
    "print(netflix_desc_duplicate)\n",
    "print(\"Repeated descriptions:\", len(netflix_desc_duplicate))\n",
    "print(\"Repeated shows:\", netflix_desc_duplicate['description'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 repeated descriptions, and a total of 15 repeated shows based on our assumption that observations with the same description are the same show. To further confirm this, we can look at the other variables of the observations corresponding to these descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df.loc[netflix_df[\"description\"].isin(netflix_desc_duplicate[\"index\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely examining the observations reveals that the only differences in the observations are the `date_added` and the `title` variables. The date when the show is added doesn't give much insight as it does not give relevant context to the similarity of the show (i.e. different versions of a show can be added at different times, and vice versa). However, the title &mdash; at least in the results above &mdash; are descriptive in the differences.\n",
    "\n",
    "The titles show that there are multiple versions due to langauge. The show *The Incredibles 2*, for instance, has both the original, and the Spanish version. Meanwhile, the movie *Oh! Baby* has two other versions: the Malalayam and Tamil. The only observation which didn't show any difference was for the movie *Sarkar* whose titles (there are 2 observations for this movie) do not indicate versions. This may either be a data collection error, or the title simply does not show which version it is.\n",
    "\n",
    "Nonetheless, all the duplicates will be cleaned in the same way. The \"original\" version (i.e. the one without a parenthesis stating the version, or if not applicable, the first entry that appears in the dataset for simplicity) will be retained. \n",
    "\n",
    "This step is important because duplicates will affect the weight of the words during feature extraction. Thus, there would be bias for a particular show which would produce results that are not representative of the show's listed genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are only few duplicates, we can manually remove the offending observations via `show_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_id_remove_list = [81186758, 81186757, 81072516, 81046962, 81059388, 81151877, 81074135, 81091424]\n",
    "\n",
    "netflix_df.loc[(netflix_df[\"description\"].isin(netflix_desc_duplicate[\"index\"])) & (~netflix_df[\"show_id\"].isin(show_id_remove_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the observations that will be retained from all the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_clean = netflix_df[~netflix_df[\"show_id\"].isin(show_id_remove_list)]\n",
    "netflix_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.) What are the top 5 genres that appear most frequently among Netflix shows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first exploratory question, we decided to determine what genres are the most frequent among Netflix shows.\n",
    "\n",
    "The genres of each Netflix show is shown in the `listed_in` column of the dataset in a single string format. Each string can contain more than one genre, and they are spearated by commas. To be able to count the frequency of each genre in the dataset, the `listed_in` column must be parsed into another table with each row containing all genres of a show, and each column containing only a single genre.\n",
    "\n",
    "First we take the `listed_in` column of the dataset and isolate the genres per Netflix show by splitting the strings at commas with spaces after them (, )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listed_in_series = netflix_df_clean['listed_in']\n",
    "genre_matrix = []\n",
    "\n",
    "for string in listed_in_series:\n",
    "    split_str = string.split(', ')\n",
    "    genre_matrix.append(split_str)\n",
    "\n",
    "genre_df = pd.DataFrame(genre_matrix)\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a table with 6226 observations and 3 columns, which means that the maximum number of genres that netflix shows are listed in is only 3. Knowing this, we can create a series by concatenating each column into one single column. Then we can drop the values which are 'None', thus cleaning the resulting series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = pd.concat([genre_df[0], genre_df[1], genre_df[2]])\n",
    "genre_list.dropna(inplace = True)\n",
    "genre_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the genres have been isolated, we can now use a bar plot to visualize the number of times a particular genre appeared on a Netflix show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genre_count = genre_list.value_counts()\n",
    "\n",
    "genre_count.plot.bar()\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar plot of genre count in Netflix shows')\n",
    "genre_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bar plot, we can see the ranking of the shows based on its frequency in Netflix shows. We see that the top 5 genres include 'International Movies', 'Dramas', 'Comedies', 'International TV Shows', and 'Documentaries'. 'International Movies' appear most frequently with 1922 appearances in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.) What is the distribution of International Movies based on thier release year in the Netflix catalogue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the bar plot of the genre frequency, 'International Movies' was determined to be the most frequent genre in the dataset. Knowing this, the second exploratory question will focus on the distribution of 'International Movies' according to its release year in the Netflix dataset. \n",
    "\n",
    "First we need to create a dataframe which only contain the shows which are listed as 'International Movies' in the dataset. However, we need to know if additional cleaning needs to be performed, since we need the columns `listed_in` and `release_year` to have values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_clean.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer need to perform additional data cleaning, since the dataset has no null values for `listed_in` or `release_year`.  We can now create the dataset which will contain the shows listed as 'International Movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netflix_df_international = netflix_df_clean\n",
    "netflix_df_international.insert(12, \"isInternationalMV\", netflix_df_clean[\"listed_in\"].str.find(\"International Movies\") != -1, True)\n",
    "netflix_df_international = netflix_df_international[netflix_df_international.isInternationalMV]\n",
    "netflix_df_international"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe which only contains the shows which have been listed as 'International Movies', we can now use a histogram in order to visualize the distribution of shows listed as 'International Movies' in the Netlflix dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netflix_df_international['release_year'].hist(bins=60)\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of International Movies per year')\n",
    "\n",
    "netflix_df_international_count_df = netflix_df_international['release_year'].value_counts()\n",
    "netflix_df_international_count_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_international.agg({\"release_year\": [\"mean\", \"std\", \"count\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the histogram above, we can describe the shape as negatively-skewed. We can see that within the Netflix catalogue, there is a larger number of shows listed as 'International Movies' which were released towards the latter half of the 2010's, with 2017 having the most number of shows. Also, we were able to determine that the standard deviation of International Movies' release years is 8.42.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.) What countries produce the most 'International Movies'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that our first exploratory question answered that shows listed as 'International Movies' were the most prominent in the Netflix dataset, the third exploratory question would determine which countries these shows most belong to. \n",
    "\n",
    "Since we already have a dataframe which contains all the shows listed as 'International Movies', we can use that dataframe for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_international['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `country` column reveals that there are some instances in which a show was produced in more than one country and these countries are separated by commas. As such, we need to parse the `country` column into another table with each row containing all countries of a show, and each column containing only a single country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df_international_country = netflix_df_international.dropna(subset=['country'])\n",
    "international_series = netflix_df_international_country['country']\n",
    "international_matrix = []\n",
    "\n",
    "for string in international_series:\n",
    "    split_str = string.split(', ')\n",
    "    international_matrix.append(split_str)\n",
    "\n",
    "international_df = pd.DataFrame(international_matrix)\n",
    "international_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a table with 1854 observations and 11 columns, which means that the maximum number of countries that the shows in our dataframe were produced in is 11. As such, we can create a series by concatenating each column into one single column. Then we can drop the values which are 'None', thus cleaning the resulting series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = pd.concat([international_df[0], international_df[1], international_df[2], international_df[3], international_df[4], international_df[5], international_df[6], international_df[7], international_df[8], international_df[9], international_df[10], international_df[11]])\n",
    "country_list.dropna(inplace = True)\n",
    "country_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the countries have been separated, we can now use a bar plot to visualize the number of 'International Movies' each country produced in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count = country_list.value_counts()\n",
    "\n",
    "country_count.plot.bar()\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar plot of distribution of International Movies based on country')\n",
    "country_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the bar plot, we see that India produced the most 'International Movies', leading by a large amount. The four other countries with the most produced movies were France, United Kingdom, Unites States, and Spain with roughly similar amounts of shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common association rules among Netflix genres?\n",
    "The shows in the netflix dataset contains a `listed_in` column which refers to what genres the shows are listed in, on the streaming platform. Usually, a show is often listed in more than one genre, and there are some genre combinations that are frequently used for shows. [A chord diagram by Dr. Shahin Rostami (2020)](https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurrence-of-movie-genres-with-chord-diagrams/#Conclusion) shows that some of the **most common genre combinations** of movies are as follows:\n",
    " - Romance and Comedy\n",
    " - Romance and Drama\n",
    " - Drama and Thriller\n",
    " - Drama and Action\n",
    " - Drama and Comedy\n",
    " - Crime and Thriller\n",
    " - Crime and Drama\n",
    " - Action and Adventure\n",
    " - Action and Thriller\n",
    " \n",
    "There are some genres that are present in the  netflix shows dataset but are not included in the chord diagram. Furthermore, some genres like 'International Movies' have a high frequency count in the dataset, which could increase the frequency of its genre combinations. We can find out if the previously mentioned genre combinations also apply on the Netflix dataset or if there are more rules associated with the most frequent genres by using **association rules**. The data preparation needed for the following steps is to drop all duplicate shows. There are some observations in the dataset that are the same show but are in different languages. These observations were already dropped in the previously done data cleaning, and the clean dataset will be used to generate the association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Modelling\n",
    "The values in the `listed_in` column are represented as strings where each string can contain more than one genre, and each genre is separated by commas. To parse these genres we need to create a matrix that is a list of genre lists, where each row represents the genres of one show. We can then use this matrix to create a dataframe that we can manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_in_series = netflix_df_clean['listed_in']\n",
    "genre_matrix = []\n",
    "\n",
    "for string in listed_in_series:\n",
    "    split_str = string.split(', ')\n",
    "    genre_matrix.append(split_str)\n",
    "\n",
    "genre_df = pd.DataFrame(genre_matrix)\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a value dictionary to assign a number to each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = genre_df.values.ravel()\n",
    "values = [value for value in pd.unique(values) if not pd.isnull(value)]\n",
    "\n",
    "value_dict = {}\n",
    "for i, value in enumerate(values):\n",
    "    value_dict[value] = i\n",
    "value_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the dictionary, we can then create a dataframe where each row is a netflix show and each column is a genre. If the show is listed in that genre then the value for that column is `1` and `0` if it is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = genre_df.stack().map(value_dict).unstack()\n",
    "\n",
    "baskets = []\n",
    "for i in range(genre_df.shape[0]):\n",
    "    basket = np.sort([int(x) for x in genre_df.iloc[i].values.tolist() if str(x) != 'nan'])\n",
    "    baskets.append(basket)\n",
    "\n",
    "shows_df = pd.DataFrame([[0 for _ in range(len(value_dict))] for _ in range(len(baskets))], columns=values)\n",
    "\n",
    "for i, basket in enumerate(baskets):\n",
    "    shows_df.iloc[i, basket] = 1\n",
    "shows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the dataframe, we can finally use a **Rule Miner** to figure out the common genre association rules of netflix shows. There can be many configurations of this Rule Miner that will produce different results. Because of this, multiple tests will be done on the dataset which will fulfill different purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first configuration will be setting the support threshold to the **lowest occurence** of a genre. This will be done to accomodate all genres in the dataset since all genres have appeared that many times. To do this we must first get all the total counts of each genre, then get the lowest value from the results. Since the total count of each genre has already been generated in the Exploratory Data Analysis, all we need to do is get the minimum value from that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last 10 results of the series\\n\")\n",
    "print(genre_count.tail(10),\"\\n\")\n",
    "print(\"Minimum no. of occurrences:\", genre_count.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of the total genre counts is `10`, which will be set as the support threshold.\n",
    "\n",
    "The confidence level is then lowered starting from `100%` until it produces at least 1 association rule\n",
    "\n",
    "From this result, we initialize the first Rule Miner to have a **support threshold** of `10` and a **confidence** of `100%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_miner_lowest_occur = RuleMiner(10, 1)\n",
    "assoc_rules_lowest_occur = rule_miner_lowest_occur.get_association_rules(shows_df)\n",
    "assoc_rules_lowest_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the get_association_rules function of the rule miner, we can see that the genre association rules are:\n",
    " - ['Crime TV Shows', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['International TV Shows', 'Science & Nature TV'] → ['Docuseries']\n",
    " - ['Science & Nature TV', 'International TV Shows'] → ['Docuseries']\n",
    " - ['Romantic TV Shows', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['TV Dramas', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['British TV Shows', 'Science & Nature TV'] → ['Docuseries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second configuration will be setting the support threshold to the **average occurence** of all genres. This will be done to make sure that the genres that will be included in the rules must have occured a sufficient number of times. We can reuse the total counts of each genre and get the mean value from the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average no. of occurrences:\", genre_count.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of the total genre counts is `324.93`, which we can round off and set as the support threshold.\n",
    "\n",
    "The confidence level is then lowered starting from `100%` until it produces at least 1 association rule\n",
    "\n",
    "From this result, we initialize this Rule Miner to have a **support threshold** of `325` and a **confidence** of `74%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_miner_mean_occur = RuleMiner(325, 0.74)\n",
    "assoc_rules_mean_occur = rule_miner_mean_occur.get_association_rules(shows_df)\n",
    "assoc_rules_mean_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the get_association_rules function of the rule miner, we can see that the only genre association rule produced is:\n",
    " - ['Independent Movies'] → ['Dramas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last configuration will be setting the support threshold to **1% of the total shows** on Netflix. This will be done to generate as many association rules as possible. We can simply multiply 0.01 to the number of rows in our dataframe to get our support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1% of total number of shows:\", len(shows_df.index)*0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1% of the total number of all shows is `62.26`, which we can round off and set as the support threshold.\n",
    "\n",
    "Additionally, we set the confidence level to `40%` to generate more rules than the previous tests.\n",
    "\n",
    "From this result, we initialize this Rule Miner to have a support threshold of `62` and a confidence of `40%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_miner_1percent = RuleMiner(62, 0.4)\n",
    "assoc_rules_1percent = rule_miner_1percent.get_association_rules(shows_df)\n",
    "assoc_rules_1percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the get_association_rules function of the rule miner, we can see that genre association rules produced are:\n",
    " - ['Comedies', 'Dramas'] → ['International Movies']\n",
    " - ['Comedies', 'Romantic Movies'] → ['International Movies']\n",
    " - ['International Movies', 'Romantic Movies'] → ['Comedies']\n",
    " - ['Comedies', 'Independent Movies'] → ['Dramas']\n",
    " - ['Crime TV Shows', 'TV Dramas'] → ['International TV Shows']\n",
    " - ['Crime TV Shows', 'International TV Shows'] → ['TV Dramas']\n",
    " - ['TV Comedies', 'Romantic TV Shows'] → ['International TV Shows']\n",
    " - [['TV Dramas', 'Romantic TV Shows'] → ['International TV Shows']\n",
    " - ['International Movies', 'Thrillers'] → ['Dramas']\n",
    " - ['Dramas', 'Thrillers'] → ['International Movies']\n",
    " - ['Action & Adventure', 'Dramas'] → ['International Movies']\n",
    " - ['International Movies', 'Independent Movies'] → ['Dramas']\n",
    " - ['Independent Movies', 'Dramas'] → ['International Movies']\n",
    " - ['International Movies', 'Romantic Movies'] → ['Dramas']\n",
    " - ['Dramas', 'Romantic Movies'] → ['International Movies']\n",
    " - ['Thrillers', 'International Movies'] → ['Dramas']\n",
    " - ['Thrillers', 'Dramas'] → ['International Movies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One limitation that was met in this research question is that there are only a maximum of 3 genres per show that is recorded in the `listed_in` column of the dataset. On the streaming platform itself, you cann actually find that there can be more than 3 genre listings per show, and this did not reflect in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first** rule miner with a support threshold of `10` and a confidence of `100%` produced the following association rules:\n",
    " - ['Crime TV Shows', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['International TV Shows', 'Science & Nature TV'] → ['Docuseries']\n",
    " - ['Science & Nature TV', 'International TV Shows'] → ['Docuseries']\n",
    " - ['Romantic TV Shows', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['TV Dramas', 'Korean TV Shows'] → ['International TV Shows']\n",
    " - ['British TV Shows', 'Science & Nature TV'] → ['Docuseries']\n",
    "\n",
    "What was interesting about this result is that even though the confidence level has not been lowered yet there were a lot of association rules generated. For the dataset, this means that whenever the itemsets on the left side of the rules are present in the `listed_in` column, the third item will always be what is on the right side of the rules generated. For Netflix, it means that there is only a very high chance of the shows following the rules generated, since not all netflix shows might be included in the dataset and there is a limit of 3 genres per show. For all shows, including those not in Netflix, there could be a lower probability of these rules being followed, since Netflix only adds shows to their streaming platform which caters to the preferences of their target market.\n",
    "\n",
    "All of the genres from these results were not included in the genre chord chart. However, it is noteable how 5 out of 6 of the generated rules contained the 'International TV Shows' genre. This genre is the 4th most frequent genre with 1001 occurrences. It may be because of the frequency that the genre appeared in these rules but it does not explain why the other top 3 most frequent genres are not included in the results. It could be due to the confidence level being very high and the rules associated with the other 3 most frequent genres do not occur 100% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **second** rule miner with a support threshold of `325` and a confidence of `74%` produced the following association rule:\n",
    " - ['Independent Movies'] → ['Dramas']\n",
    " \n",
    "This result is interesting as there are only two genres in the rules. The rule states that whenever a show is listed as an 'Independent Movie' it has a 74% chance of also being listed in 'Dramas'. It could be derived that a lot of Independent or 'Indie' movies are dramas. During this time, Indie Movies are popular for winning awards or for simply being good. There could be a trend of indie drama movies that support the rule generated but that is a different question with a different solution to arrive at the answer.\n",
    "\n",
    "Another interesting observation is that none of the genres from the first set of association rules made it to the current results. This could mean that their itemsets had low support which removed them from the set of frequent itemsets used to generate the rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **third** rule miner with a support threshold of `62` and a confidence of `40%` produced the following association rules:\n",
    " - ['Comedies', 'Dramas'] → ['International Movies']\n",
    " - ['Comedies', 'Romantic Movies'] → ['International Movies']\n",
    " - ['International Movies', 'Romantic Movies'] → ['Comedies']\n",
    " - ['Comedies', 'Independent Movies'] → ['Dramas']\n",
    " - ['Crime TV Shows', 'TV Dramas'] → ['International TV Shows']\n",
    " - ['Crime TV Shows', 'International TV Shows'] → ['TV Dramas']\n",
    " - ['TV Comedies', 'Romantic TV Shows'] → ['International TV Shows']\n",
    " - [['TV Dramas', 'Romantic TV Shows'] → ['International TV Shows']\n",
    " - ['International Movies', 'Thrillers'] → ['Dramas']\n",
    " - ['Dramas', 'Thrillers'] → ['International Movies']\n",
    " - ['Action & Adventure', 'Dramas'] → ['International Movies']\n",
    " - ['International Movies', 'Independent Movies'] → ['Dramas']\n",
    " - ['Independent Movies', 'Dramas'] → ['International Movies']\n",
    " - ['International Movies', 'Romantic Movies'] → ['Dramas']\n",
    " - ['Dramas', 'Romantic Movies'] → ['International Movies']\n",
    " - ['Thrillers', 'International Movies'] → ['Dramas']\n",
    " - ['Thrillers', 'Dramas'] → ['International Movies']\n",
    " \n",
    "The rules generated by this third rule miner are reflective of the common genre combinations that can be found from [Dr. Shahin Rostami's chord diagram.](https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurrence-of-movie-genres-with-chord-diagrams/#Conclusion) Each combination from the combinations 'Romance and Comedy', 'Romance and Drama', 'Drama and Thriller', 'Drama and Action', 'Drama and Comedy', and 'Crime and Drama', all appear in at least one rule from the generated results. The only combinations not present are 'Action and Thriller', Crime and Thriller, and Action and Adventure, which is a single genre on its own. The only genres in the results that are not in the chord chart are 'International Movies', 'International TV Shows', and 'Independent Movies'. In addition, the top 4 most frequent genres are included in this dataset, including other frequently listed genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the question, \"What are the most common association rules among Netflix genres?\", it would be the association rules generated by the **third rule miner** with a support of `62` and a confidence of `40%`. This is because the first rule miner did not have frequent enough itemsets, that the results it generated can no longer be found in the other rule miners. It is also notable that a confidence of 100% is too strict for association rules that do not occur one hundred percent of the time. The second rule miner also has a high support threshold, which eliminates some frequent enough itemsets. Additionally, the confidence level was too high especially for a rule miner with a high support threshold. The second rule miner limited and eliminated too many rules that could have been meaningful. The third rule miner had a sufficiently low support threshold of `62`, which accomodated a lot of itemsets. The confidence level of `40%` also increased the number of association rules generated, and it is not too low since the itemsets are already frequent enough and there are not too many rules generated.\n",
    "\n",
    "If further improvements could be made, it would be finding a specific value for the support threshold to say that a set of genre combinations occurs frequently enough. Additionally, it would be better to find and use a dataset that would not limit the number of genres a show could be listed in. This could create more meaningful rules which could help in answering other questions like genre trends or help in creating netflix user profiles for recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are Netflix synopses informative enough to classify whether shows belong to the International Movies genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `description` variable in the dataset refers to Netflix's synopsis of each show. For this research question, the idea is to determine whether these synopses are informative enough to classify whether a show is classified under *International Movies*. This entails building a classifier which would be able to identify all *International Movie* shows in the dataset.\n",
    "\n",
    "This is interesting because the problem leads to more questions about how informative Netflix synopses are. Are plots &mdash; represented by the synopses &mdash; dependent of genre? Are stories similar for the same genre? Are words able to represent genres? These will not be answered in this research problem, but are indications of the many stimulating possibilities that this research problem entails. It's also an indication of the capabilities of computers in handling natural language.\n",
    "\n",
    "The *International Movies* genre is chosen because 1,922 shows are classified under this genre which makes it the most prominent. Choosing a prominent genre is important because there is a need to have a good amount of samples; this is especially true for classification which requires good representatives for each categories &mdash; in this case, the categories are \"International Movies\" and \"Not International Movies\". For this problem, only the `description` and `listed_in` variables from the Netflix dataset will be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classification, two sets of data are needed: data which contains only shows with *International Movies* as its genre (regardless whether it's also classified as other genres), and data containing shows which are not classified under *International Movies*.\n",
    "\n",
    "In the exploratory data analysis, there's already a `DataFrame` pertaining to the first. What we need is a `DataFrame` for shows that aren't classified under *International Movies*. To do this, the `isInternationalMV` variable from `netflix_df_clean`, can be used where False values indicates that show is not under said classification. After getting the False values, the next step is to concatenate both \"Not International Movies\" and \"International Movies\" data together to prepare it for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_df_non_international = netflix_df_clean[netflix_df_clean[\"isInternationalMV\"] == False]\n",
    "netflix_df_non_international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netflix_df_classifier = pd.concat([netflix_df_non_international, netflix_df_international])\n",
    "netflix_df_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"International Movies:\", len(netflix_df_international))\n",
    "print(\"Not International Movies:\", len(netflix_df_non_international))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Total International Movies shows:** 1922 shows\n",
    "\n",
    "- **Total Not International Movies shows:** 4304 shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "The `description` variable is in the form of sentences (naturally, because synopses are written with words). The task is to evaluate the value of words in these synposes.  However, computers do not really understand sentences. Hence, a mathematical model is important to transform the words into a numerical representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "The term frequency-inverse document frequency (TF-IDF) is a statistical method which places value in words through an inverse proportion of the word's frequency in a document, in this case the `description`, to the amount of documents the word appears in. The importance of a word is indicated by a high TF-IDF value. The TF-IDF value is given by the formula: \n",
    "\n",
    "$$W_{i,j} = tf_{i,j} \\times log{N \\over df_{i}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$tf_{i,j}$ = number of occurences of $i$ in $j$,\n",
    "\n",
    "$df_{i}$ = number of documents containing $i$, and\n",
    "\n",
    "$N$ = total number of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's [TF-IDF Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) was utilized to transform the `description` column into a matrix of TF-IDF features. First we fit the documents (i.e. the synposes) by using the vectorizer's `fit` function for the vectorizer to learn the vocabulary. Once vectorizer knows the vocabulary and document frequencies, the `transform` function is used to transform the documents into a document-term matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(netflix_df_classifier[\"description\"])\n",
    "features=vectorizer.transform(netflix_df_classifier[\"description\"])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the TF-IDF Vectorizer converted the `description` column into a sparse matrix of TF-IDF values where each row contains 16411 columns. This also means that there are 16411 words that were extracted as features from the dataset. To confirm this, we can get the word form of the features from the vectorizer by using its `get_feature_names` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_words = vectorizer.get_feature_names()\n",
    "print(features_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a list of all the words, sorted alphabetically, that the vectorizer learned and, consequently, used as features to build the sparse matrix. Results show that there are indeed 16411 features for each row (and thus, for each show)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing labels\n",
    "In order for the classifier to classify, it should be trained knowing the labels &mdash; in this case *International Movie* or *Not International Movie* &mdash; of the show it's trying to classify. The next step is to prepare these labels by utilizing the `isInternationalMV` variable of the dataset to form an array of labels. *International Movie* shows are represented as 1s, while *Not International Movie* shows are represented as 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for show in netflix_df_classifier[\"isInternationalMV\"]:\n",
    "    if show == True:\n",
    "        appenddata=1\n",
    "    if show == False:\n",
    "        appenddata=0\n",
    "    labels.append(appenddata)\n",
    "    \n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because *Not International Movie* shows and *International Movie* shows were simply concatenated, it's expected that the dataset is split homogenously where the first parts are all *Not International Movie* shows and the latter are *International Movie* shows. This is not a problem, however, since a stratified cross-validation approach will be utilized which splits the data such that there will be close-as-possible distribution of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a classifier and measuring performance\n",
    "This [chart](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) from scikit-learn was utilized to choose the right estimator for this problem. The circumstances of this research lead us to selecting [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) from scikit-learn's support vector machine module.\n",
    "\n",
    "Feeding the data to the machine algorithm can be manually done by using the functions of the `LinearSVC` class. However, as mentioned earlier, cross-validation will be used in evaluating the performance of the dataset. For this purpose,  [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) will allow us to both build the classifier, and evaluate its performance at the same time. For binary classification problems such as what we have, `cross_validate` automatically uses the [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) as its cross-validation splitter, hence, we minimize having bias in each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to initialize the estimator (Linear SVC), and name the metrics/scoring that will be used by the cross-validation in evaluating performance. Default parameters were used for the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearSVC=svm.LinearSVC()\n",
    "scoring = ['accuracy', 'recall', 'precision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we simply use the estimator, the features, the labels, and the scorers as parameters for `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(linearSVC, features, labels, scoring=scoring)\n",
    "print('Mean Accuracy:', scores['test_accuracy'].mean())\n",
    "print('Accuracy Two Standard Deviations:', scores['test_accuracy'].std() * 2)\n",
    "print('Mean Precision', scores['test_precision'].mean())\n",
    "print('Mean Recall', scores['test_recall'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **95% Confidence Interval of Genre Classifier Accuracy:** 72.23% $\\pm$ 2.98\n",
    "\n",
    "- **Average Genre Classifier Precision:** 57.83%\n",
    "\n",
    "- **Average Genre Classifier Recall:** 39.80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more information, we can extract the top features by using [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest#sklearn.feature_selection.SelectKBest) which returns the top *k* features based on a scoring function. In this case, we will use [`Chi-squared statistics`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2)because it is expected that the features &mdash; in the form of TF-IDF values &mdash; will never be negative. Furthermore, because chi-squared statistics measures dependence between variables, it can be used to determine which features are independent of classes, hence, not useful in classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=20)\n",
    "selector.fit(features, labels)\n",
    "# Get idxs of columns to keep\n",
    "top_features_idxs = selector.get_support(indices=True)\n",
    "\n",
    "scores, pval=(chi2(features, labels))\n",
    "\n",
    "chi2_data={'Feature Names': np.array(features_words)[top_features_idxs], 'Chi2': scores[top_features_idxs], 'P-value': pval[top_features_idxs]}\n",
    "features_chi2 = pd.DataFrame(chi2_data).sort_values(by=['Chi2'], ascending=False, ignore_index=True)\n",
    "features_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` shows the top 20 most class-dependent features identified through chi-squared statistics. When the classifier sees these words in the synopses, there is a high probability that it would be able to classify whether the show is an *International Movie* or not correctly.\n",
    "\n",
    "Note, however, that the results are based on the evaluation of the data as a whole (i.e. did not follow the cross-validation scheme), and without consideration of the machine learning algorithm. The implication is that it may not be representative of the the accuracy of the classifiers that were measured during cross-validation. Nevertheless, this method still shows a general idea of what the top features would be for a classifier that is built with synopses and genre data from the Netflix dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "The 95% confidence interval for a Netflix genre classifier's accuracy is 72.23% $\\pm$ 2.98. This means that the classifier, more than half of the time, was able to classify whether a show is an *International Movie* or *Not International Movie*. Only considering accuracy, this can be interpreted as successful.\n",
    "\n",
    "However, even though a stratified cross-validation was used, there is still some class imbalance because the dataset contains 1,922 *International Movie* shows, and 4,304 *Not International Movie* shows. The latter class is more than twice the other. This renders the accuracy measure an inferior evaluator because it can yield a high accuracy even if it fails to classify a lot of International Movie shows.\n",
    "\n",
    "For instance, if the classifier were to correctly guess all *Not International Movie* shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intl_total = 1922\n",
    "non_intl_total = 4304\n",
    "    \n",
    "non_intl_total / (intl_total + non_intl_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy would be 69.13% which can still be interpreted as the classifier being able to correctly classify more than half the time. Given so, we can look at [precision and recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall). The former is concerned with the correct *International Movie* show predictions, while the latter is concerned with the number of actual *International Movie* shows that were identified by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall\n",
    "The average precision for the classifiers is 57.83%. This means that more than half the time, when the classifiers predict a show to be under *International Movies*, it is true. Meanwhile, the average recall for the classifiers is 39.80%. This means that the classifiers were only able to identify less than half of all the *International Movie* shows. Given a standard of 50%, the classifiers were not successful at all.\n",
    "\n",
    "Given that the goal was to correctly identify all *International Movies* shows from the data, precision is much less important than recall. As such, looking at recall, we can say that although accuracy is high, the classifiers are not able to satisfactorily identify the *International Movie* shows.\n",
    "\n",
    "However, this means that accuracy is truly affected by the class imbalance. The implication is that the classifier were probably able to classify *Not International Movie* shows, at least better than its counterpart. To test this we can flip the labels to say that the true positives are the *Not International Movie* shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_labels=[]\n",
    "for show in netflix_df_classifier[\"isInternationalMV\"]:\n",
    "    if show == True:\n",
    "        appenddata=0\n",
    "    if show == False:\n",
    "        appenddata=1\n",
    "    invert_labels.append(appenddata)\n",
    "    \n",
    "invert_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_scores = cross_validate(linearSVC, features, invert_labels, scoring=scoring)\n",
    "print('Mean Precision', invert_scores['test_precision'].mean())\n",
    "print('Mean Recall', invert_scores['test_recall'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Average Precision:** 76.34%\n",
    "\n",
    "- **Average Recall:** 86.71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show an astounding increase in performance. Recall increased more than twice which indicates that the classifiers were able to predict most of the *Not International Movie* shows in the dataset. \n",
    "\n",
    "Thus, it can still be said that synopses are still informative in genre classification, just the other way around. In future studies, a better way to test this is to have a dataset that have equal, or close distribution of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Features\n",
    "The top class-dependent features also gives insight about the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the table, there words that can be identified to match with the idea of an international movie:\n",
    "- Bollywood\n",
    "- India\n",
    "- Indian\n",
    "- Mumbai\n",
    "- Caste\n",
    "\n",
    "Under a 0.05 significance level, these are all hugely relevant to the classification process. It's also worth noting that these words are all related to India. This result is consistent with the findings in the exploratory data analysis stating that most of the shows that fall under the *International Movies* genre &mdash; 714 shows to be exact &mdash; is produced in India."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it is expected that the chi-squared statistics, given a set of *International Movies* shows, most of which are produced in India, would find Indian-related words to be relevant features for classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, based on analysis, it can be said that Netflix synopses are not informative enough in classifying if shows belong to the International Movies genre. However, if the goal was identifying the opposite, Netflix synopses prove to be informative. In this latter context, performance metrics reveal that the classifier was able to perform well given only show synopses and their corresponding genre. \n",
    "\n",
    "Meanwhile, a brief top-features analysis show that synopses contain information, specifically words, that are relevant to its genre, and consequently, the classification. \n",
    "\n",
    "In the future, it is recommended to conduct parameter tuning for the estimator to see whether there are better parameters that would yield better classifier performance; a better performance may conclude that the problem was not due to the dataset, but with the classifier's setup. Another recommendation is to consider other metrics such as the confusion matrix to further analyze results and why the classifier behaves the way it does. It is also recommended that further data preprocessing techniques be done such as lemmatization, and stop words removal. Finally, in line with the chi-squared statistics of finding the top features, further analysis can be done to find out which words can describe *International Movies* in Netflix. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
